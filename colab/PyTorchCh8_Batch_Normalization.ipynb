{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorchCh8_Batch_Normalization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMYg6ysGSz31Wb/GkFxnloF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b48ecc1e629847568377781fd57615f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cdf25c6a5a6f4cf4abd3e30455e2d06e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c067d9a6a7764206a9b8a6e8927cab6c",
              "IPY_MODEL_9c072ac7d0d84c4291e57ab8084f1965",
              "IPY_MODEL_a67b40b3a1124262aea1e9ec62a9334d"
            ]
          }
        },
        "cdf25c6a5a6f4cf4abd3e30455e2d06e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c067d9a6a7764206a9b8a6e8927cab6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d22634463ba144408cf4d4fc14c14ee4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_11c431c04fb649c8a0a1c74db31f94b0"
          }
        },
        "9c072ac7d0d84c4291e57ab8084f1965": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_51eccf2093a64d50a9cfc71827df74ad",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_18b3b1dee7034367a246b16b10a89242"
          }
        },
        "a67b40b3a1124262aea1e9ec62a9334d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_428f45b19d5f4918a84c8ecc092de731",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:03&lt;00:00, 56622868.63it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bfe0c91c100740e894c0126d7180048b"
          }
        },
        "d22634463ba144408cf4d4fc14c14ee4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "11c431c04fb649c8a0a1c74db31f94b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "51eccf2093a64d50a9cfc71827df74ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "18b3b1dee7034367a246b16b10a89242": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "428f45b19d5f4918a84c8ecc092de731": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bfe0c91c100740e894c0126d7180048b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bitdribble/dlwpt-code/blob/master/colab/PyTorchCh8_Batch_Normalization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGTi82xep0qr",
        "outputId": "2195c6f2-af71-4c8b-d253-d602197c5cc8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7efb33cabb50>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import datetime\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "torch.set_printoptions(edgeitems=2, linewidth=75)\n",
        "torch.manual_seed(123)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preparation\n",
        "data_path = '.'\n",
        "cifar10 = datasets.CIFAR10(data_path, train=True, download=True)\n",
        "cifar10_val = datasets.CIFAR10(data_path, train=False, download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "b48ecc1e629847568377781fd57615f4",
            "cdf25c6a5a6f4cf4abd3e30455e2d06e",
            "c067d9a6a7764206a9b8a6e8927cab6c",
            "9c072ac7d0d84c4291e57ab8084f1965",
            "a67b40b3a1124262aea1e9ec62a9334d",
            "d22634463ba144408cf4d4fc14c14ee4",
            "11c431c04fb649c8a0a1c74db31f94b0",
            "51eccf2093a64d50a9cfc71827df74ad",
            "18b3b1dee7034367a246b16b10a89242",
            "428f45b19d5f4918a84c8ecc092de731",
            "bfe0c91c100740e894c0126d7180048b"
          ]
        },
        "id": "tO9YQMmtqx7J",
        "outputId": "f53394a5-541d-49c0-d561-1cf03eafa7d8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b48ecc1e629847568377781fd57615f4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./cifar-10-python.tar.gz to .\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize data\n",
        "transformed_cifar10 = datasets.CIFAR10(\n",
        "    data_path, train=True, download=False,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))\n",
        "transformed_cifar10_val = datasets.CIFAR10(\n",
        "    data_path, train=False, download=False,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))"
      ],
      "metadata": {
        "id": "CqOmZYEvrCoU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Restrict data to airplanes and birds\n",
        "label_map = {0: 0, 2: 1}\n",
        "class_names = ['airplane', 'bird']\n",
        "\n",
        "cifar2 = [(img, label_map[label]) for img, label in transformed_cifar10 if label in [0, 2]]\n",
        "cifar2_val = [(img, label_map[label]) for img, label in transformed_cifar10_val if label in [0, 2]]"
      ],
      "metadata": {
        "id": "wQc7w_JfrGdK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
        "print(f\"Training on device {device}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peDeR2fvrRhc",
        "outputId": "33df9181-7810-4897-d62e-7ba87f8b1c3a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on device cuda.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(n_epochs, device, optimizer, model, loss_fn, train_loader, log_epochs=0):\n",
        "  for epoch in range(1, n_epochs + 1):\n",
        "    loss_train = 0.0\n",
        "\n",
        "    for imgs, labels in train_loader:\n",
        "      imgs = imgs.to(device=device)\n",
        "      labels = labels.to(device=device)\n",
        "\n",
        "      outputs = model(imgs)\n",
        "      loss = loss_fn(outputs, labels)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      loss_train += loss.item()\n",
        "\n",
        "    if log_epochs is not 0 and ((epoch+1) % log_epochs == 0 or (epoch+1) == n_epochs):\n",
        "      print(f\"{datetime.datetime.now()} Epoch {epoch+1}, \"\n",
        "            f\"Training loss {loss_train / len(train_loader):.3f}\")\n",
        "\n",
        "def validate(model, device, train_loader, val_loader):\n",
        "  for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad(): \n",
        "      for imgs, labels in loader:\n",
        "        imgs = imgs.to(device=device)\n",
        "        labels = labels.to(device=device)\n",
        "\n",
        "        outputs = model(imgs)\n",
        "        _, predicted = torch.max(outputs, dim=1) \n",
        "\n",
        "        total += labels.shape[0]\n",
        "        correct += int((predicted == labels).sum())\n",
        "\n",
        "\n",
        "    print(f\"Accuracy {name}: {correct / total:.2f}\")"
      ],
      "metadata": {
        "id": "FLrRsGJbrZKu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch Normalization allows us to increase the learning rate and make\n",
        "# training less dependent on initialization and act as a regularizer, thus representing an\n",
        "# alternative to dropout.\n",
        "#\n",
        "# Paper: https://arxiv.org/abs/1502.03167\n",
        "#\n",
        "# Batch normalization rescales the inputs to the activations\n",
        "# of the network so that minibatches have a certain desirable distribution. Recalling\n",
        "# the  mechanics  of  learning  and  the  role  of  nonlinear  activation  functions,  this\n",
        "# helps avoid the inputs to activation functions being too far into the saturated portion\n",
        "# of the function, thereby killing gradients and slowing training.\n",
        "# \n",
        "# In  practical  terms,  batch  normalization  shifts  and  scales  an  intermediate  input\n",
        "# using  the  mean  and  standard  deviation  collected  at  that  intermediate  location  over\n",
        "# the samples of the minibatch. The regularization effect is a result of the fact that an\n",
        "# individual  sample  and  its  downstream  activations  are  always  seen  by  the  model  as\n",
        "# shifted  and  scaled,  depending  on  the  statistics  across  the  randomly  extracted  mini-\n",
        "# batch.  This  is  in  itself  a  form  of  principled  augmentation.  The  authors  of  the  paper\n",
        "# suggest  that  using  batch  normalization  eliminates  or  at  least  alleviates  the  need\n",
        "# for dropout.\n",
        "#\n",
        "# Batch normalization in PyTorch is provided through the nn.BatchNorm1D,\n",
        "# nn.BatchNorm2d, and nn.BatchNorm3d modules, depending on the dimensionality of\n",
        "# the input. Since the aim for batch normalization is to rescale the inputs of the activa-\n",
        "# tions, the natural location is after the linear transformation (convolution, in this case)\n",
        "# and the activation, as shown here\n",
        "\n",
        "class NetBatchNorm(nn.Module):\n",
        "  def __init__(self, n_chans1=32):\n",
        "    super().__init__()\n",
        "\n",
        "    self.n_chans1 = n_chans1\n",
        "    self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
        "    self.conv1_batchnorm = nn.BatchNorm2d(num_features=n_chans1)\n",
        "    self.act1 = nn.Tanh()\n",
        "    self.pool1 = nn.MaxPool2d(2)\n",
        "\n",
        "    self.conv2 = nn.Conv2d(n_chans1, n_chans1//2, kernel_size=3, padding=1)\n",
        "    self.conv2_batchnorm = nn.BatchNorm2d(num_features=n_chans1//2)\n",
        "    self.act2 = nn.Tanh()\n",
        "    self.pool2 = nn.MaxPool2d(2)\n",
        "\n",
        "    self.fc1 = nn.Linear(8*8*(n_chans1//2), 32)\n",
        "    self.act3 = nn.Tanh()\n",
        "\n",
        "    self.fc2 = nn.Linear(32, 2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.pool1(self.act1(self.conv1_batchnorm(self.conv1(x))))\n",
        "    out = self.pool2(self.act2(self.conv2_batchnorm(self.conv2(out))))\n",
        "    out = out.view(-1, 8*8*(self.n_chans1//2)) # In place of nn.Flatten()\n",
        "    out = self.act3(self.fc1(out))\n",
        "    out = self.fc2(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "EMPREzM0sFgP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropout is normally active during training, while during the evaluation of a\n",
        "# trained model in production, dropout is bypassed or, equivalently, assigned a proba-\n",
        "# bility  equal  to  zero.  This  is  controlled  through  the  train  property  of  the  Dropout\n",
        "# module. Recall that PyTorch lets us switch between the two modalities by calling\n",
        "#\n",
        "# model.train()\n",
        "#\n",
        "# or\n",
        "#\n",
        "# model.eval()\n",
        "#\n",
        "# on any nn.Model subclass. The call will be automatically replicated on the submodules\n",
        "# so  that  if  Dropout  is  among  them,  it  will  behave  accordingly  in  subsequent  forward\n",
        "# and backward passes."
      ],
      "metadata": {
        "id": "sI62cmO-ZC_h"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NetBatchNorm(n_chans1=32).to(device=device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=True)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "model.train() # Set train mode\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 100,\n",
        "    device=device,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_loader,\n",
        "    log_epochs = 10\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8FVyS1jr3jI",
        "outputId": "1f4d6628-1846-48f4-8bbd-1a82330a1664"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-01-31 00:11:44.997435 Epoch 10, Training loss 0.281\n",
            "2022-01-31 00:11:54.801778 Epoch 20, Training loss 0.223\n",
            "2022-01-31 00:12:04.735258 Epoch 30, Training loss 0.177\n",
            "2022-01-31 00:12:14.561481 Epoch 40, Training loss 0.136\n",
            "2022-01-31 00:12:24.380778 Epoch 50, Training loss 0.105\n",
            "2022-01-31 00:12:34.332574 Epoch 60, Training loss 0.082\n",
            "2022-01-31 00:12:44.247117 Epoch 70, Training loss 0.059\n",
            "2022-01-31 00:12:54.184916 Epoch 80, Training loss 0.039\n",
            "2022-01-31 00:13:04.168679 Epoch 90, Training loss 0.031\n",
            "2022-01-31 00:13:14.120098 Epoch 100, Training loss 0.023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Just as for dropout, batch normalization needs to behave differently during training\n",
        "# and inference. In fact, at inference time, we want to avoid having the output for a spe-\n",
        "# cific input depend on the statistics of the other inputs we’re presenting to the model.\n",
        "# As  such,  we  need  a  way  to  still  normalize,  but  this  time  fixing  the  normalization\n",
        "# parameters once and for all.\n",
        "#\n",
        "# As  minibatches  are  processed,  in  addition  to  estimating  the  mean  and  standard\n",
        "# deviation for the current minibatch, PyTorch also updates the running estimates for\n",
        "# mean  and  standard  deviation  that  are  representative  of  the  whole  dataset,  as  an\n",
        "# approximation. This way, when the user specifies\n",
        "#\n",
        "# model.eval()\n",
        "# \n",
        "# and the model contains a batch normalization module, the running estimates are fro-\n",
        "# zen  and  used  for  normalization. To unfreeze  running estimates  and  return  to using\n",
        "# the minibatch statistics, we call model.train(), just as we did for dropout. "
      ],
      "metadata": {
        "id": "zz_HKPKU_l0V"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=False)\n",
        "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64, shuffle=False)\n",
        "\n",
        "model.eval() # Set eval mode\n",
        "\n",
        "validate(model, device, train_loader, val_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-ekEAk1xqWl",
        "outputId": "f900d435-1d0c-4324-ebd6-f142f0e28b7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy train: 1.00\n",
            "Accuracy val: 0.88\n"
          ]
        }
      ]
    }
  ]
}